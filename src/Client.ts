/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as environments from "./environments";
import * as core from "./core";
import * as Vellum from "./api";
import * as serializers from "./serialization";
import urlJoin from "url-join";
import * as errors from "./errors";
import * as stream from "stream";
import { Deployments } from "./api/resources/deployments/client/Client";
import { DocumentIndexes } from "./api/resources/documentIndexes/client/Client";
import { Documents } from "./api/resources/documents/client/Client";
import { ModelVersions } from "./api/resources/modelVersions/client/Client";
import { RegisteredPrompts } from "./api/resources/registeredPrompts/client/Client";
import { Sandboxes } from "./api/resources/sandboxes/client/Client";
import { TestSuites } from "./api/resources/testSuites/client/Client";

export declare namespace VellumClient {
    interface Options {
        environment?: core.Supplier<environments.VellumEnvironment | environments.VellumEnvironmentUrls>;
        apiKey: core.Supplier<string>;
    }

    interface RequestOptions {
        timeoutInSeconds?: number;
        maxRetries?: number;
    }
}

export class VellumClient {
    constructor(protected readonly _options: VellumClient.Options) {}

    /**
     * Executes a deployed Prompt and returns the result.
     *
     * Note: This endpoint temporarily does not support prompts with function calling, support is coming soon.
     * In the meantime, we recommend still using the `/generate` endpoint for prompts with function calling.
     * @throws {@link Vellum.BadRequestError}
     * @throws {@link Vellum.ForbiddenError}
     * @throws {@link Vellum.NotFoundError}
     * @throws {@link Vellum.InternalServerError}
     */
    public async executePrompt(
        request: Vellum.ExecutePromptRequest,
        requestOptions?: VellumClient.RequestOptions
    ): Promise<Vellum.ExecutePromptResponse> {
        const _response = await core.fetcher({
            url: urlJoin(
                ((await core.Supplier.get(this._options.environment)) ?? environments.VellumEnvironment.Production)
                    .predict,
                "v1/execute-prompt"
            ),
            method: "POST",
            headers: {
                X_API_KEY: await core.Supplier.get(this._options.apiKey),
                "X-Fern-Language": "JavaScript",
                "X-Fern-SDK-Name": "vellum-ai",
                "X-Fern-SDK-Version": "v0.1.13",
            },
            contentType: "application/json",
            body: await serializers.ExecutePromptRequest.jsonOrThrow(request, { unrecognizedObjectKeys: "strip" }),
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : undefined,
            maxRetries: requestOptions?.maxRetries,
        });
        if (_response.ok) {
            return await serializers.ExecutePromptResponse.parseOrThrow(_response.body, {
                unrecognizedObjectKeys: "passthrough",
                allowUnrecognizedUnionMembers: true,
                allowUnrecognizedEnumValues: true,
                breadcrumbsPrefix: ["response"],
            });
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 400:
                    throw new Vellum.BadRequestError(_response.error.body);
                case 403:
                    throw new Vellum.ForbiddenError(_response.error.body);
                case 404:
                    throw new Vellum.NotFoundError(_response.error.body);
                case 500:
                    throw new Vellum.InternalServerError(_response.error.body);
                default:
                    throw new errors.VellumError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                    });
            }
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.VellumError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                });
            case "timeout":
                throw new errors.VellumTimeoutError();
            case "unknown":
                throw new errors.VellumError({
                    message: _response.error.errorMessage,
                });
        }
    }

    /**
     * Executes a deployed Prompt and streams back the results.
     *
     * Note: This endpoint temporarily does not support prompts with function calling, support is coming soon.
     * In the meantime, we recommend still using the `/generate-stream` endpoint for prompts with function calling
     */
    public async executePromptStream(
        request: Vellum.ExecutePromptStreamRequest,
        requestOptions?: VellumClient.RequestOptions
    ): Promise<core.Stream<Vellum.ExecutePromptEvent>> {
        const _response = await core.fetcher<stream.Readable>({
            url: urlJoin(
                ((await core.Supplier.get(this._options.environment)) ?? environments.VellumEnvironment.Production)
                    .predict,
                "v1/execute-prompt-stream"
            ),
            method: "POST",
            headers: {
                X_API_KEY: await core.Supplier.get(this._options.apiKey),
                "X-Fern-Language": "JavaScript",
                "X-Fern-SDK-Name": "vellum-ai",
                "X-Fern-SDK-Version": "v0.1.13",
            },
            contentType: "application/json",
            body: await serializers.ExecutePromptStreamRequest.jsonOrThrow(request, {
                unrecognizedObjectKeys: "strip",
            }),
            responseType: "streaming",
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : undefined,
            maxRetries: requestOptions?.maxRetries,
        });
        if (_response.ok) {
            return new core.Stream({
                stream: _response.body,
                terminator: "\n",
                parse: async (data) => {
                    return await serializers.ExecutePromptEvent.parseOrThrow(data, {
                        unrecognizedObjectKeys: "passthrough",
                        allowUnrecognizedUnionMembers: true,
                        allowUnrecognizedEnumValues: true,
                        breadcrumbsPrefix: ["response"],
                    });
                },
            });
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 400:
                    throw new Vellum.BadRequestError(_response.error.body);
                case 403:
                    throw new Vellum.ForbiddenError(_response.error.body);
                case 404:
                    throw new Vellum.NotFoundError(_response.error.body);
                case 500:
                    throw new Vellum.InternalServerError(_response.error.body);
                default:
                    throw new errors.VellumError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                    });
            }
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.VellumError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                });
            case "timeout":
                throw new errors.VellumTimeoutError();
            case "unknown":
                throw new errors.VellumError({
                    message: _response.error.errorMessage,
                });
        }
    }

    /**
     * Executes a deployed Workflow and streams back its results.
     */
    public async executeWorkflowStream(
        request: Vellum.ExecuteWorkflowStreamRequest,
        requestOptions?: VellumClient.RequestOptions
    ): Promise<core.Stream<Vellum.WorkflowStreamEvent>> {
        const _response = await core.fetcher<stream.Readable>({
            url: urlJoin(
                ((await core.Supplier.get(this._options.environment)) ?? environments.VellumEnvironment.Production)
                    .predict,
                "v1/execute-workflow-stream"
            ),
            method: "POST",
            headers: {
                X_API_KEY: await core.Supplier.get(this._options.apiKey),
                "X-Fern-Language": "JavaScript",
                "X-Fern-SDK-Name": "vellum-ai",
                "X-Fern-SDK-Version": "v0.1.13",
            },
            contentType: "application/json",
            body: await serializers.ExecuteWorkflowStreamRequest.jsonOrThrow(request, {
                unrecognizedObjectKeys: "strip",
            }),
            responseType: "streaming",
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : undefined,
            maxRetries: requestOptions?.maxRetries,
        });
        if (_response.ok) {
            return new core.Stream({
                stream: _response.body,
                terminator: "\n",
                parse: async (data) => {
                    return await serializers.WorkflowStreamEvent.parseOrThrow(data, {
                        unrecognizedObjectKeys: "passthrough",
                        allowUnrecognizedUnionMembers: true,
                        allowUnrecognizedEnumValues: true,
                        breadcrumbsPrefix: ["response"],
                    });
                },
            });
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 400:
                    throw new Vellum.BadRequestError(_response.error.body);
                case 404:
                    throw new Vellum.NotFoundError(_response.error.body);
                case 500:
                    throw new Vellum.InternalServerError(_response.error.body);
                default:
                    throw new errors.VellumError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                    });
            }
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.VellumError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                });
            case "timeout":
                throw new errors.VellumTimeoutError();
            case "unknown":
                throw new errors.VellumError({
                    message: _response.error.errorMessage,
                });
        }
    }

    /**
     * Generate a completion using a previously defined deployment.
     *
     * **Note:** Uses a base url of `https://predict.vellum.ai`.
     * @throws {@link Vellum.BadRequestError}
     * @throws {@link Vellum.ForbiddenError}
     * @throws {@link Vellum.NotFoundError}
     * @throws {@link Vellum.InternalServerError}
     *
     * @example
     *     await vellum.generate({
     *         requests: [{
     *                 inputValues: {}
     *             }],
     *         options: {
     *             logprobs: Vellum.LogprobsEnum.All
     *         }
     *     })
     */
    public async generate(
        request: Vellum.GenerateBodyRequest,
        requestOptions?: VellumClient.RequestOptions
    ): Promise<Vellum.GenerateResponse> {
        const _response = await core.fetcher({
            url: urlJoin(
                ((await core.Supplier.get(this._options.environment)) ?? environments.VellumEnvironment.Production)
                    .predict,
                "v1/generate"
            ),
            method: "POST",
            headers: {
                X_API_KEY: await core.Supplier.get(this._options.apiKey),
                "X-Fern-Language": "JavaScript",
                "X-Fern-SDK-Name": "vellum-ai",
                "X-Fern-SDK-Version": "v0.1.13",
            },
            contentType: "application/json",
            body: await serializers.GenerateBodyRequest.jsonOrThrow(request, { unrecognizedObjectKeys: "strip" }),
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : undefined,
            maxRetries: requestOptions?.maxRetries,
        });
        if (_response.ok) {
            return await serializers.GenerateResponse.parseOrThrow(_response.body, {
                unrecognizedObjectKeys: "passthrough",
                allowUnrecognizedUnionMembers: true,
                allowUnrecognizedEnumValues: true,
                breadcrumbsPrefix: ["response"],
            });
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 400:
                    throw new Vellum.BadRequestError(_response.error.body);
                case 403:
                    throw new Vellum.ForbiddenError(_response.error.body);
                case 404:
                    throw new Vellum.NotFoundError(_response.error.body);
                case 500:
                    throw new Vellum.InternalServerError(_response.error.body);
                default:
                    throw new errors.VellumError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                    });
            }
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.VellumError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                });
            case "timeout":
                throw new errors.VellumTimeoutError();
            case "unknown":
                throw new errors.VellumError({
                    message: _response.error.errorMessage,
                });
        }
    }

    /**
     * Generate a stream of completions using a previously defined deployment.
     *
     * **Note:** Uses a base url of `https://predict.vellum.ai`.
     */
    public async generateStream(
        request: Vellum.GenerateStreamBodyRequest,
        requestOptions?: VellumClient.RequestOptions
    ): Promise<core.Stream<Vellum.GenerateStreamResponse>> {
        const _response = await core.fetcher<stream.Readable>({
            url: urlJoin(
                ((await core.Supplier.get(this._options.environment)) ?? environments.VellumEnvironment.Production)
                    .predict,
                "v1/generate-stream"
            ),
            method: "POST",
            headers: {
                X_API_KEY: await core.Supplier.get(this._options.apiKey),
                "X-Fern-Language": "JavaScript",
                "X-Fern-SDK-Name": "vellum-ai",
                "X-Fern-SDK-Version": "v0.1.13",
            },
            contentType: "application/json",
            body: await serializers.GenerateStreamBodyRequest.jsonOrThrow(request, { unrecognizedObjectKeys: "strip" }),
            responseType: "streaming",
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : undefined,
            maxRetries: requestOptions?.maxRetries,
        });
        if (_response.ok) {
            return new core.Stream({
                stream: _response.body,
                terminator: "\n",
                parse: async (data) => {
                    return await serializers.GenerateStreamResponse.parseOrThrow(data, {
                        unrecognizedObjectKeys: "passthrough",
                        allowUnrecognizedUnionMembers: true,
                        allowUnrecognizedEnumValues: true,
                        breadcrumbsPrefix: ["response"],
                    });
                },
            });
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 400:
                    throw new Vellum.BadRequestError(_response.error.body);
                case 403:
                    throw new Vellum.ForbiddenError(_response.error.body);
                case 404:
                    throw new Vellum.NotFoundError(_response.error.body);
                case 500:
                    throw new Vellum.InternalServerError(_response.error.body);
                default:
                    throw new errors.VellumError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                    });
            }
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.VellumError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                });
            case "timeout":
                throw new errors.VellumTimeoutError();
            case "unknown":
                throw new errors.VellumError({
                    message: _response.error.errorMessage,
                });
        }
    }

    /**
     * Perform a search against a document index.
     *
     * **Note:** Uses a base url of `https://predict.vellum.ai`.
     * @throws {@link Vellum.BadRequestError}
     * @throws {@link Vellum.NotFoundError}
     * @throws {@link Vellum.InternalServerError}
     */
    public async search(
        request: Vellum.SearchRequestBodyRequest,
        requestOptions?: VellumClient.RequestOptions
    ): Promise<Vellum.SearchResponse> {
        const _response = await core.fetcher({
            url: urlJoin(
                ((await core.Supplier.get(this._options.environment)) ?? environments.VellumEnvironment.Production)
                    .predict,
                "v1/search"
            ),
            method: "POST",
            headers: {
                X_API_KEY: await core.Supplier.get(this._options.apiKey),
                "X-Fern-Language": "JavaScript",
                "X-Fern-SDK-Name": "vellum-ai",
                "X-Fern-SDK-Version": "v0.1.13",
            },
            contentType: "application/json",
            body: await serializers.SearchRequestBodyRequest.jsonOrThrow(request, { unrecognizedObjectKeys: "strip" }),
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : undefined,
            maxRetries: requestOptions?.maxRetries,
        });
        if (_response.ok) {
            return await serializers.SearchResponse.parseOrThrow(_response.body, {
                unrecognizedObjectKeys: "passthrough",
                allowUnrecognizedUnionMembers: true,
                allowUnrecognizedEnumValues: true,
                breadcrumbsPrefix: ["response"],
            });
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 400:
                    throw new Vellum.BadRequestError(_response.error.body);
                case 404:
                    throw new Vellum.NotFoundError(_response.error.body);
                case 500:
                    throw new Vellum.InternalServerError(_response.error.body);
                default:
                    throw new errors.VellumError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                    });
            }
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.VellumError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                });
            case "timeout":
                throw new errors.VellumTimeoutError();
            case "unknown":
                throw new errors.VellumError({
                    message: _response.error.errorMessage,
                });
        }
    }

    /**
     * Used to submit feedback regarding the quality of previously generated completions.
     *
     * **Note:** Uses a base url of `https://predict.vellum.ai`.
     * @throws {@link Vellum.BadRequestError}
     * @throws {@link Vellum.NotFoundError}
     * @throws {@link Vellum.InternalServerError}
     *
     * @example
     *     await vellum.submitCompletionActuals({
     *         actuals: []
     *     })
     */
    public async submitCompletionActuals(
        request: Vellum.SubmitCompletionActualsRequest,
        requestOptions?: VellumClient.RequestOptions
    ): Promise<void> {
        const _response = await core.fetcher({
            url: urlJoin(
                ((await core.Supplier.get(this._options.environment)) ?? environments.VellumEnvironment.Production)
                    .predict,
                "v1/submit-completion-actuals"
            ),
            method: "POST",
            headers: {
                X_API_KEY: await core.Supplier.get(this._options.apiKey),
                "X-Fern-Language": "JavaScript",
                "X-Fern-SDK-Name": "vellum-ai",
                "X-Fern-SDK-Version": "v0.1.13",
            },
            contentType: "application/json",
            body: await serializers.SubmitCompletionActualsRequest.jsonOrThrow(request, {
                unrecognizedObjectKeys: "strip",
            }),
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : undefined,
            maxRetries: requestOptions?.maxRetries,
        });
        if (_response.ok) {
            return;
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 400:
                    throw new Vellum.BadRequestError(_response.error.body);
                case 404:
                    throw new Vellum.NotFoundError(_response.error.body);
                case 500:
                    throw new Vellum.InternalServerError(_response.error.body);
                default:
                    throw new errors.VellumError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                    });
            }
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.VellumError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                });
            case "timeout":
                throw new errors.VellumTimeoutError();
            case "unknown":
                throw new errors.VellumError({
                    message: _response.error.errorMessage,
                });
        }
    }

    /**
     *     Used to submit feedback regarding the quality of previous workflow execution and its outputs.
     *
     *     **Note:** Uses a base url of `https://predict.vellum.ai`.
     *
     * @example
     *     await vellum.submitWorkflowExecutionActuals({
     *         actuals: []
     *     })
     */
    public async submitWorkflowExecutionActuals(
        request: Vellum.SubmitWorkflowExecutionActualsRequest,
        requestOptions?: VellumClient.RequestOptions
    ): Promise<void> {
        const _response = await core.fetcher({
            url: urlJoin(
                ((await core.Supplier.get(this._options.environment)) ?? environments.VellumEnvironment.Production)
                    .predict,
                "v1/submit-workflow-execution-actuals"
            ),
            method: "POST",
            headers: {
                X_API_KEY: await core.Supplier.get(this._options.apiKey),
                "X-Fern-Language": "JavaScript",
                "X-Fern-SDK-Name": "vellum-ai",
                "X-Fern-SDK-Version": "v0.1.13",
            },
            contentType: "application/json",
            body: await serializers.SubmitWorkflowExecutionActualsRequest.jsonOrThrow(request, {
                unrecognizedObjectKeys: "strip",
            }),
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : undefined,
            maxRetries: requestOptions?.maxRetries,
        });
        if (_response.ok) {
            return;
        }

        if (_response.error.reason === "status-code") {
            throw new errors.VellumError({
                statusCode: _response.error.statusCode,
                body: _response.error.body,
            });
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.VellumError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                });
            case "timeout":
                throw new errors.VellumTimeoutError();
            case "unknown":
                throw new errors.VellumError({
                    message: _response.error.errorMessage,
                });
        }
    }

    protected _deployments: Deployments | undefined;

    public get deployments(): Deployments {
        return (this._deployments ??= new Deployments(this._options));
    }

    protected _documentIndexes: DocumentIndexes | undefined;

    public get documentIndexes(): DocumentIndexes {
        return (this._documentIndexes ??= new DocumentIndexes(this._options));
    }

    protected _documents: Documents | undefined;

    public get documents(): Documents {
        return (this._documents ??= new Documents(this._options));
    }

    protected _modelVersions: ModelVersions | undefined;

    public get modelVersions(): ModelVersions {
        return (this._modelVersions ??= new ModelVersions(this._options));
    }

    protected _registeredPrompts: RegisteredPrompts | undefined;

    public get registeredPrompts(): RegisteredPrompts {
        return (this._registeredPrompts ??= new RegisteredPrompts(this._options));
    }

    protected _sandboxes: Sandboxes | undefined;

    public get sandboxes(): Sandboxes {
        return (this._sandboxes ??= new Sandboxes(this._options));
    }

    protected _testSuites: TestSuites | undefined;

    public get testSuites(): TestSuites {
        return (this._testSuites ??= new TestSuites(this._options));
    }
}
