/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as Vellum from "../../../../index";

/**
 * @example
 *     {
 *         name: "name",
 *         family: Vellum.MlModelFamily.Capybara,
 *         execConfig: {
 *             modelIdentifier: "model_identifier",
 *             baseUrl: "base_url",
 *             metadata: {
 *                 "key": "value"
 *             },
 *             features: [Vellum.MlModelFeature.Text]
 *         }
 *     }
 */
export interface MlModelCreateRequest {
    /** The unique name of the ML Model. */
    name: string;
    /**
     * The family of the ML Model.
     *
     * * `CAPYBARA` - Capybara
     * * `CHAT_GPT` - Chat GPT
     * * `CLAUDE` - Claude
     * * `COHERE` - Cohere
     * * `FALCON` - Falcon
     * * `GEMINI` - Gemini
     * * `GRANITE` - Granite
     * * `GPT3` - GPT-3
     * * `FIREWORKS` - Fireworks
     * * `LLAMA2` - Llama2
     * * `LLAMA3` - Llama3
     * * `MISTRAL` - Mistral
     * * `MPT` - MPT
     * * `OPENCHAT` - OpenChat
     * * `PALM` - PaLM
     * * `SOLAR` - Solar
     * * `TITAN` - Titan
     * * `WIZARD` - Wizard
     * * `YI` - Yi
     * * `ZEPHYR` - Zephyr
     */
    family: Vellum.MlModelFamily;
    /**
     * The organization hosting the ML Model.
     *
     * * `ANTHROPIC` - ANTHROPIC
     * * `AWS_BEDROCK` - AWS_BEDROCK
     * * `AZURE_OPENAI` - AZURE_OPENAI
     * * `COHERE` - COHERE
     * * `CUSTOM` - CUSTOM
     * * `FIREWORKS_AI` - FIREWORKS_AI
     * * `GOOGLE` - GOOGLE
     * * `GOOGLE_VERTEX_AI` - GOOGLE_VERTEX_AI
     * * `GROQ` - GROQ
     * * `HUGGINGFACE` - HUGGINGFACE
     * * `IBM_WATSONX` - IBM_WATSONX
     * * `MOSAICML` - MOSAICML
     * * `MYSTIC` - MYSTIC
     * * `OPENAI` - OPENAI
     * * `OPENPIPE` - OPENPIPE
     * * `PYQ` - PYQ
     * * `REPLICATE` - REPLICATE
     */
    hostedBy?: Vellum.HostedByEnum;
    /**
     * The organization that developed the ML Model.
     *
     * * `01_AI` - 01_AI
     * * `AMAZON` - AMAZON
     * * `ANTHROPIC` - ANTHROPIC
     * * `COHERE` - COHERE
     * * `ELUTHERAI` - ELUTHERAI
     * * `FIREWORKS_AI` - FIREWORKS_AI
     * * `GOOGLE` - GOOGLE
     * * `HUGGINGFACE` - HUGGINGFACE
     * * `IBM` - IBM
     * * `META` - META
     * * `MISTRAL_AI` - MISTRAL_AI
     * * `MOSAICML` - MOSAICML
     * * `NOUS_RESEARCH` - NOUS_RESEARCH
     * * `OPENAI` - OPENAI
     * * `OPENCHAT` - OPENCHAT
     * * `OPENPIPE` - OPENPIPE
     * * `TII` - TII
     * * `WIZARDLM` - WIZARDLM
     */
    developedBy?: Vellum.MlModelDeveloper;
    /** Configuration for how the ML Model was built. */
    buildConfig?: Vellum.MlModelBuildConfigRequest;
    /** Configuration for how to execute the ML Model. */
    execConfig: Vellum.MlModelExecConfigRequest;
    /** Configuration for the ML Model's parameters. */
    parameterConfig?: Vellum.MlModelParameterConfigRequest;
    /** Configuration for how to display the ML Model. */
    displayConfig?: Vellum.MlModelDisplayConfigRequest;
    /**
     * The visibility of the ML Model.
     *
     * * `DEFAULT` - DEFAULT
     * * `PUBLIC` - PUBLIC
     * * `PRIVATE` - PRIVATE
     * * `DISABLED` - DISABLED
     */
    visibility?: Vellum.VisibilityEnum;
}
