/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as Vellum from "..";

export interface ModelVersionRead {
    /** Vellum-generated ID that uniquely identifies this model version. */
    id: string;
    /** Timestamp of when this model version was created. */
    created: Date;
    /** Human-friendly name for this model version. */
    label: string;
    /**
     * Which LLM provider this model version is associated with.
     *
     * - `ANTHROPIC` - Anthropic
     * - `AWS_BEDROCK` - AWS Bedrock
     * - `AZURE_OPENAI` - Azure OpenAI
     * - `COHERE` - Cohere
     * - `GOOGLE` - Google
     * - `HOSTED` - Hosted
     * - `MOSAICML` - MosaicML
     * - `OPENAI` - OpenAI
     * - `FIREWORKS_AI` - Fireworks AI
     * - `HUGGINGFACE` - HuggingFace
     * - `MYSTIC` - Mystic
     * - `PYQ` - Pyq
     * - `REPLICATE` - Replicate
     */
    provider: Vellum.ProviderEnum;
    /** The unique id of this model version as it exists in the above provider's system. */
    externalId: string;
    /** Configuration used to build this model version. */
    buildConfig: Vellum.ModelVersionBuildConfig;
    /** Configuration used to execute this model version. */
    execConfig: Vellum.ModelVersionExecConfig;
    status?: Vellum.ModelVersionReadStatusEnum;
}
